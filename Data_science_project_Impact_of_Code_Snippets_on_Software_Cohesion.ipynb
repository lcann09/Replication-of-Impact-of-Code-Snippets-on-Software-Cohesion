{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dV7Y-6x8d-g4"
      },
      "outputs": [],
      "source": [
        "# !pip install pygithub\n",
        "# !pip install pprintpp\n",
        "# !pip install javalang\n",
        "# !pip install http://www.boddie.org.uk/python/downloads/javaclass-0.2.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajGcRcellWzE"
      },
      "source": [
        "## Get commits from GitHub based on Stack Overflow info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSW8fnXPeBvM"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import javalang\n",
        "import requests as req\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Get commits from GitHub based on Stack Overflow info\n",
        "def get_commits(user, repo, filepath, snippet=\"//stackoverflow.com\"):\n",
        "    file_tokens = filepath.split(\"/\")\n",
        "\n",
        "    commits = OrderedDict()\n",
        "    earliest_sha_containing_snippet = None\n",
        "\n",
        "    try:\n",
        "        resp = req.request(method='GET', url=\"https://api.github.com/repos/\"+user+\"/\"+repo+\"/commits?path=\" + filepath, headers={'Authorization': 'token ' +'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'})\n",
        "    except req.exceptions.RequestException as e: \n",
        "        raise SystemExit(e)\n",
        "    json = resp.json()\n",
        "    for i in range(len(json)):\n",
        "        # GET https://api.github.com/repos/:owner/:repo/contents/:FILE_PATH?ref=SHA\n",
        "        try:\n",
        "            sha = json[i][\"sha\"]\n",
        "        except Exception:\n",
        "            continue\n",
        "        try:\n",
        "            resp_temp = req.request(method='GET', url=\"https://api.github.com/repos/\"+user+\"/\"+repo+\"/contents/\"+filepath+\"?ref=\"+sha, headers={'Authorization': 'token ' +'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'})\n",
        "        except req.exceptions.RequestException as e: \n",
        "            raise SystemExit(e)\n",
        "        json_committed_file = resp_temp.json()\n",
        "        # if (not \"content\" in json_committed_file) or (\"message\" in json_committed_file and json_committed_file[\"message\"]=='Not Found'):\n",
        "        #   continue\n",
        "        try:\n",
        "            content = base64.b64decode(json_committed_file[\"content\"])\n",
        "        except Exception:\n",
        "            continue\n",
        "        \n",
        "        commits[(sha)] = content\n",
        "        if snippet in str(content):\n",
        "            earliest_sha_containing_snippet = sha\n",
        "\n",
        "    return commits, earliest_sha_containing_snippet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMBevRUCseaR",
        "outputId": "b0362f7f-675f-4fab-f328-190804f2e626"
      },
      "outputs": [],
      "source": [
        "# Test get_commits function\n",
        "\n",
        "user = \"GunoH\"\n",
        "repo = \"intellij-community\"\n",
        "filepath = \"plugins/tasks/tasks-core/jira/src/com/intellij/tasks/jira/soap/JiraLegacyApi.java\"\n",
        "snippet = \"//stackoverflow.com\"\n",
        "\n",
        "complete_commits, earliest_sha_containing_snippet = get_commits(user, repo, filepath, snippet)\n",
        "print(earliest_sha_containing_snippet)\n",
        "print(complete_commits)\n",
        "print(list(complete_commits.keys()).index(earliest_sha_containing_snippet))\n",
        "print(list(complete_commits.keys())[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QFcSmpMlZzN"
      },
      "source": [
        "## Calculate metrics from the commit information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ka5qKBqoznN",
        "outputId": "32327569-2f33-4c8f-e4c2-1190385a2425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import javalang\n",
        "\n",
        "# Calculate metrics from the commit information\n",
        "def analyze(s):\n",
        "  all_attrs = []\n",
        "  tree = javalang.parse.parse(s)\n",
        "  num_attrs = len(list(tree.filter(javalang.tree.FieldDeclaration)))\n",
        "  num_methods = len(list(tree.filter(javalang.tree.MethodDeclaration)))\n",
        "  num_methods_for_attrs = [0 for i in range(num_attrs)]\n",
        "\n",
        "  \n",
        "  for path, node in tree.filter(javalang.tree.FieldDeclaration):\n",
        "      all_attrs.append(str(node.declarators[0].name))\n",
        "  methods_attrs = []\n",
        "  for path, node in tree.filter(javalang.tree.MethodDeclaration):\n",
        "      method_attrs = set()\n",
        "      for i in range(num_attrs):\n",
        "          attr = all_attrs[i]\n",
        "          if attr in str(node):\n",
        "              method_attrs.add(attr)\n",
        "              num_methods_for_attrs[i] = num_methods_for_attrs[i]+1\n",
        "      methods_attrs.append(method_attrs)\n",
        "\n",
        "\n",
        "  # Calculate LSCC  (Written by Spencer Goudswaard)\n",
        "  MAR = num_methods_for_attrs\n",
        "\n",
        "  k = num_methods\n",
        "  l = num_attrs\n",
        "  LSCC = 0\n",
        "  # LSCC formula calculation\n",
        "  if (l == 0 and k > l):\n",
        "      LSCC = 0\n",
        "  elif ((l > 0 and k == 0) or k == 1):\n",
        "      LSCC = 1\n",
        "  else:\n",
        "      for x in MAR:\n",
        "          LSCC += x*(x-1)\n",
        "      LSCC = LSCC/(l*k*(k-1))\n",
        "\n",
        "\n",
        "  # Calculate Class Cohesion (CC)  (Written by Spencer Goudswaard)\n",
        "  CC = 0\n",
        "\n",
        "  # Need to pull these values out of the GH files\n",
        "  I = methods_attrs # The sets represent the attributes referenced by a method.\n",
        "\n",
        "  # CC formula calculation\n",
        "  for i in range(1,k-1):\n",
        "      for j in range(i+1,k):\n",
        "          if not len(I[i-1].union(I[j-1])) == 0:\n",
        "            CC += len(I[i-1].intersection(I[j-1]))/len(I[i-1].union(I[j-1]))\n",
        "  if k==1 or k==0:\n",
        "    CC=1\n",
        "  else:\n",
        "    CC = 2*CC/(k*(k-1))\n",
        "  return LSCC, CC\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aK_gVRIlcEw"
      },
      "source": [
        "## Using file from the Big Query database to pull info about GitHub commits and analyse them for calculation of metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL77zGaO5-pa"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import webbrowser\n",
        "rows = []\n",
        "\n",
        "\n",
        "# Using file from the Big Query database to pull info about GitHub commits and analyse them for calculation of metrics\n",
        "with open(\"samples.csv\", 'r') as csvfile, open('data.csv', 'w') as csv_out:\n",
        "  csvreader = csv.reader(csvfile)\n",
        "  csvwriter = csv.writer(csv_out)\n",
        "  row_num = -1\n",
        "  for row in csvreader:\n",
        "        row_num = row_num + 1\n",
        "        row = row[:-12]\n",
        "        if csvreader.line_num ==1:\n",
        "          continue\n",
        "        repo = row[3]\n",
        "        user = row[2]\n",
        "        filepath = row[5]\n",
        "        snippet = \"//stackoverflow.com\"\n",
        "        commits, earliest_sha_containing_snippet = get_commits(user, repo, filepath, snippet)\n",
        "        if earliest_sha_containing_snippet == None:\n",
        "          continue\n",
        "        earliest_index = list(commits.keys()).index(earliest_sha_containing_snippet)\n",
        "        \n",
        "        earliest_before_index = earliest_index + 1\n",
        "\n",
        "        if earliest_before_index >= len(list(commits.keys())):\n",
        "          continue\n",
        "\n",
        "        try: \n",
        "          for i in range(earliest_before_index, -1, -1):\n",
        "            content = list(commits.items())[i][1]\n",
        "            val1, val2 = analyze(content)\n",
        "            row.append([val1,val2])\n",
        "          csvwriter.writerow(row)\n",
        "        except Exception:\n",
        "          continue\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PPNWY3hleov"
      },
      "source": [
        "## Output final data analysis results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obwnDdS-2Tff"
      },
      "outputs": [],
      "source": [
        "# Output final data analysis results\n",
        "data0, data1, data2, data3 = None, None, None, None\n",
        "\n",
        "with open('data-0.csv') as fp:\n",
        "    data0 = fp.read()\n",
        "  \n",
        "# Reading data from file2\n",
        "with open('data-1.csv') as fp:\n",
        "    data1 = fp.read()\n",
        "with open('data-2.csv') as fp:\n",
        "    data2 = fp.read()\n",
        "with open('data-3.csv') as fp:\n",
        "    data3 = fp.read()\n",
        "  \n",
        "# Merging 2 files\n",
        "# To add the data of file2\n",
        "# from next line\n",
        "data0 += \"\\n\"\n",
        "data1 += \"\\n\"\n",
        "data2 += \"\\n\"\n",
        "\n",
        "data0 += data1\n",
        "data0 += data2\n",
        "data0 += data3\n",
        "  \n",
        "with open ('data_combined.csv', 'w') as fp:\n",
        "    fp.write(data0)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Data science project - Impact of Code Snippets on Software Cohesion.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
